## Hi there ðŸ‘‹

 ðŸ‘‹ Iâ€™m **Muzzamil Nagda**, a  Data Engineer with a passion for transforming raw data into actionable insights through efficient ETL pipelines and cloud technologies.

 ðŸš€ **ETL Projects**:
I have practical experience in developing scalable ETL solutions using tools like **Azure Data Factory**, **Databricks**, and **Synapse Analytics**. My projects include **cloud migrations**, **data quality management**, and **automation of reporting pipelines**. Check out the repositories below to explore more!

ðŸ”§ **Tech Stack:**  
- **Cloud Platforms:** Azure, Microsoft Fabric  
- **Languages & Tools:** PySpark, SQL, Power BI  
- **Data Management:** Lakehouse architecture, Blob Storage, Datalake Gen2

ðŸ’¬ Feel free to reach out if you want to **collaborate**, discuss **data engineering** best practices, or simply talk about **innovative data solutions**.

## My latest projects
<!-- TODO 
        1. add your new project below this line
        2. Put first paragraph as description
        3. copy architecture image and paste it using 
<img src=TODO alt="drawing" width="600"/>
        4. Delete last project in this file (last ###)
-->

### Building daily news pipeline in Fabric
This project streamlines the process of gathering and analyzing the latest news by utilizing the Bing Web Search API in combination with Microsoft Fabric. Designed to collect fresh news daily, it applies sentiment analysis to each article and visualizes the results through a Power BI dashboard. Built with Microsoft Fabric tools like Data Factory, Lakehouse, Jupyter Notebooks, and Power BI, the pipeline provides efficient data orchestration, processing, and visualization. Configured alerts signal the arrival of new data, supporting prompt reviews and insights.
<img src=https://github.com/muzzamilanis/muzzamilanis/blob/main/ArchitectureDiagramOfBingNewsAPI.png alt="drawing" width="1000"/>

### Tokyo-olympic-azure-data-engineering-project
This project explores the Tokyo Olympics data, leveraging Azureâ€™s powerful data engineering services to perform end-to-end data processing and analysis. Following Darshil Parmar's tutorial, the project covers data ingestion, transformation, and storage in a scalable pipeline. It uses Azure Data Factory for orchestration, Azure Databricks for data transformation, Azure Data Lake Storage for scalable storage, and Azure Synapse Analytics for data warehousing and analysis. Visual insights are generated through Power BI, creating a comprehensive data workflow that offers insights into Olympic performance, trends, and statistics.
<img src=https://github.com/muzzamilanis/tokyo-olympic-azure-data-engineering-project/blob/muzzamilanis-olympics-data-dashboard/Architecture%20diagram%20of%20Data%20engineering%20on%20Tokyo%20olympics%20data.png alt="drawing" width="1000" />
